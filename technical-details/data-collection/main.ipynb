{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Data Collection\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include overview.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "{{< include methods.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Note: person user details are concealed\n",
    "client_id = ''\n",
    "client_secret = ''\n",
    "user_agent = ''\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent\n",
    ")\n",
    "\n",
    "# Test if connected\n",
    "print(reddit.read_only)  # Expected True\n",
    "\n",
    "try:\n",
    "    # Test with subreddit: python\n",
    "    subreddit = reddit.subreddit('python')\n",
    "    print(f\"Successfully connected! Subreddit title: {subreddit.title}\")\n",
    "    print(f\"Read-only mode: {reddit.read_only}\")  # True Expected\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_subreddit = \"data/processed-data/subreddits.csv\"\n",
    "df_subreddit = pd.read_csv(file_path_subreddit)\n",
    "subreddit_list = df_subreddit['subreddit'].tolist()\n",
    "\n",
    "# Storage for results\n",
    "results = []\n",
    "\n",
    "# Counters for submission and comments\n",
    "submission_count = 0\n",
    "comment_count = 0\n",
    "\n",
    "# Function to convert UTC timestamp to readable format\n",
    "def convert_timestamp(utc_timestamp):\n",
    "    return datetime.fromtimestamp(utc_timestamp, timezone.utc).strftime('%Y/%m')\n",
    "\n",
    "# Iterate over each subreddit\n",
    "for subreddit_name in subreddit_list:\n",
    "    print(f\"Fetching data for subreddit: {subreddit_name}\")\n",
    "    try:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "        \n",
    "        # Store post IDs to avoid duplicates\n",
    "        seen_post_ids = set()\n",
    "        \n",
    "        # Submission Collection Part 1: Get top 10 posts by hot ranking\n",
    "        for submission in subreddit.hot(limit=10):\n",
    "            \n",
    "            # Skip repeat submission\n",
    "            if submission.id in seen_post_ids:\n",
    "                continue\n",
    "\n",
    "            # Skip posts with the \"meme\" flair\n",
    "            if submission.link_flair_text and \"meme\" in submission.link_flair_text.lower():\n",
    "                print(f\"Skipping post with 'meme' flair: {submission.title}\")\n",
    "                continue\n",
    "\n",
    "            submission_data = {\n",
    "                \"subreddit\": subreddit_name,\n",
    "                \"post_id\": submission.id,\n",
    "                \"title\": submission.title,\n",
    "                \"text\": submission.selftext,\n",
    "                \"score\": submission.score,\n",
    "                \"created_utc\": convert_timestamp(submission.created_utc),\n",
    "                \"sort_type\": \"hot\",\n",
    "                \"comments\": []\n",
    "            }\n",
    "\n",
    "            seen_post_ids.add(submission.id)\n",
    "            submission_count += 1\n",
    "\n",
    "            # Process comments for this submission\n",
    "            submission.comments.replace_more(limit=0)  \n",
    "            all_comments = submission.comments.list()\n",
    "            \n",
    "            # Sort comments by number of replies\n",
    "            comments_by_replies = sorted(\n",
    "                all_comments,\n",
    "                key=lambda x: len(x.replies) if hasattr(x, 'replies') else 0,\n",
    "                reverse=True\n",
    "            )[:10]\n",
    "            \n",
    "            # Process comments and add indentation\n",
    "            def process_comments(comments, depth=0):\n",
    "                global comment_count\n",
    "                processed_comments = []\n",
    "                \n",
    "                for comment in comments:\n",
    "                    # indent = \"  \" * depth  \n",
    "                    processed_comment = {\n",
    "                        \"comment_id\": comment.id,\n",
    "                        \"body\": comment.body,\n",
    "                        \"score\": comment.score,\n",
    "                        \"depth\": depth,\n",
    "                        \"num_replies\": len(comment.replies) if hasattr(comment, 'replies') else 0,\n",
    "                        \"created_utc\": convert_timestamp(comment.created_utc)  \n",
    "                    }\n",
    "                    \n",
    "                    comment_count += 1\n",
    "                    processed_comments.append(processed_comment)\n",
    "                    \n",
    "                    # Process replies if they exist\n",
    "                    if hasattr(comment, 'replies') and len(comment.replies) > 0:\n",
    "                        replies = list(comment.replies)[:10]  # Limit replies to 10 per comment\n",
    "                        processed_comments.extend(process_comments(replies, depth + 1))\n",
    "                \n",
    "                return processed_comments\n",
    "\n",
    "            # Process and store comments for the current submission\n",
    "            submission_data[\"comments\"] = process_comments(comments_by_replies)\n",
    "            results.append(submission_data)\n",
    "\n",
    "\n",
    "        # Submission Collection Part 2: Get top 10 posts by controversial ranking\n",
    "        for submission in subreddit.controversial(limit=10):\n",
    "            if submission.id in seen_post_ids:\n",
    "                continue\n",
    "                \n",
    "            # Skip posts with the \"meme\" flair\n",
    "            if submission.link_flair_text and \"meme\" in submission.link_flair_text.lower():\n",
    "                print(f\"Skipping post with 'meme' flair: {submission.title}\")\n",
    "                continue\n",
    "            \n",
    "            submission_data = {\n",
    "                \"subreddit\": subreddit_name,\n",
    "                \"post_id\": submission.id,\n",
    "                \"title\": submission.title,\n",
    "                \"text\": submission.selftext,\n",
    "                \"score\": submission.score,\n",
    "                \"created_utc\": convert_timestamp(submission.created_utc),  \n",
    "                \"sort_type\": \"controversial\",  \n",
    "                \"comments\": []\n",
    "            }\n",
    "            \n",
    "            seen_post_ids.add(submission.id)\n",
    "            submission_count += 1\n",
    "\n",
    "            # Process comments for this submission\n",
    "            submission.comments.replace_more(limit=0)\n",
    "            all_comments = submission.comments.list()\n",
    "            \n",
    "            # Sort comments by number of replies\n",
    "            comments_by_replies = sorted(\n",
    "                all_comments,\n",
    "                key=lambda x: len(x.replies) if hasattr(x, 'replies') else 0,\n",
    "                reverse=True\n",
    "            )[:10]\n",
    "            \n",
    "            # Process and store comments using the same process_comments function\n",
    "            submission_data[\"comments\"] = process_comments(comments_by_replies)\n",
    "            results.append(submission_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for subreddit {subreddit_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Print summary of fetched data\n",
    "print(f\"Total posts fetched: {submission_count}\")\n",
    "print(f\"Total comments fetched: {comment_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{< include closing.qmd >}} "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
