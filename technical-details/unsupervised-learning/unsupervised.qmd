---
title: "Unsupervised Learning"
bibliography: ../../assets/references.bib
output: html_document
---

# Overview

Unsupervised learning is a type of machine learning that involves training a model without labeled data. The goal is to explore the underlying structure of the data by identifying patterns or clusters without predefined categories.

In this project, **NMF (Non-negative Matrix Factorization)** and **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)** were used to analyze and cluster texts of posts and comments into meaningful groups.

# Dimensionality Reduction

1.  **PCA (Principal Component Analysis):**

    -   **Process**:

        -   Applied PCA to the dataset to reduce dimensions while preserving variance.

        -   Determined that 263 components were needed to retain 80% of the variance, suggesting that the data has high dimensionality.

    -   **Conclusion**: Although PCA reduces dimensions, the number of components required suggests that the data remains complex and sparse.

    ![](../../image/pca_vr_nc.png)

    This plot illustrates the results of PCA. The x-axis represents the number of principal components, while the y-axis shows the cumulative explained variance ratio. Notably, 263 principal components are required to explain over 80% of the variance, indicating the high-dimensional complexity of the data.

2.  **t-SNE (t-distributed Stochastic Neighbor Embedding):**

    -   **Process**:

        -   t-SNE was implemented with perplexities of 5, 30, and 50.

        -   Each perplexity parameter controls how local or global the clustering visualization appears.

    -   **Comparison**:

        -   t-SNE provided a visually appealing reduction of the data but did not reveal well-separated clusters.

        -   Compared to PCA, t-SNE offers better visualization but no clear interpretable patterns emerged. ![](../../image/t-SNE_perplexity.png)

    These three subplots shows the t-SNE visualization with different perplexity values (5, 30, and 50). As the perplexity value increases, the data points transition from a more scattered local structure to a smoother global structure.

# NMF (Non-negative Matrix Factorization)

NMF is a factorization technique that decomposes a matrix (in this case, the term-document matrix) into two non-negative matrices: one representing topics and the other representing words. NMF is particularly useful for discovering parts-based representations in data, making it suitable for text data where topics can be described by sets of relevant words.

## **Reasons for Choosing NMF**

-   **Topic interpretability**: NMF provides topics described by sets of semantically meaningful words.
-   **Sparsity**: Non-negative constraints ensure additivity, yielding easily interpretable results.

## Process

1.  **Text Preprocessing:** The text is first cleaned by removing stopwords, performing lemmatization, and retaining only nouns, adjectives, verbs, and adverbs.

2.  **TF-IDF Vectorization:** The text data is transformed into a sparse matrix of term frequency-inverse document frequency (TF-IDF) features.

3.  **Topic Modeling with NMF:** The NMF model is trained with 5 topics, using the TF-IDF features. The model identifies the topics by associating high-weighted words with each topic.

4.  **Topic Assignment:** The highest topic probabilities for each document are assigned, and the comments' labels are associated with the posts they are from.

## **Results**

NMF identified the following 5 relatively distinct topics:

| Topic | Top Words                                             | Simplified Theme            |
|-------|-------------------------------------------------------|-----------------------------|
| 0     | challenge, abortion, daily, democracy, cover, attack  | Abortion and Women’s Rights |
| 1     | abortion, attack, agree, bodily, blame, counter       | Abortion Debate             |
| 2     | counter, body, bodily, attack, democracy, belief      | Body and Beliefs            |
| 3     | bodily, body, donate, believe, democracy, border      | Body and Democracy          |
| 4     | birth, assume, care, background check, attack, cancel | Birth and Background Checks |

![](../../image/topics_visualized_pca_tsne.png)

The first subplot shows the distribution of different topics (represented by colors) in the PCA-reduced space. A certain degree of overlap between topics is observed, suggesting that some texts may involve multiple themes simultaneously.

This second subplot displays the distribution of different topics (represented by colors) in the t-SNE-reduced space. The results are similar to those observed in the PCA space, reflecting the interconnected nature of the topics.

# DBSCAN

DBSCAN is a density-based clustering algorithm that groups together closely packed points and marks isolated points as noise. Unlike other clustering algorithms, DBSCAN does not require the number of clusters to be specified in advance.

## Reasons for Choosing DBSCAN

-   **Noise Handling:** DBSCAN can handle noisy data and outliers effectively.

-   **Cluster Shape Flexibility:** It does not assume spherical clusters, making it suitable for data with irregular cluster shapes.

## Process

1.  **TF-IDF Vectorization:** The text data is transformed into TF-IDF vectors, same as the NMF approach.

2.  **Standardization:** The TF-IDF vectors are standardized (scaled) before applying DBSCAN to ensure that all features are treated equally.

3.  **Clustering with DBSCAN:** DBSCAN is applied to the scaled TF-IDF vectors with `eps=0.5` and `min_samples=5.`

4.  **Validation with k-distance Plot:** The k-distance plot is generated to analyze the density distribution.

## **Results**

DBSCAN finds only 1 cluster, with 672 samples marked as noise (-1) and 5 sample points assigned to cluster 0.

| NMF Topic | Cluster -1 (Noise) | Cluster 0 |
|-----------|--------------------|-----------|
| 0         | 32                 | 0         |
| 1         | 65                 | 0         |
| 2         | 209                | 5         |
| 3         | 210                | 0         |
| 4         | 156                | 0         |

![This clustering results plot presents the findings of DBSCAN clustering in the t-SNE-reduced space. DBSCAN identified one dominant cluster, indicating that most data points are relatively concentrated within the feature space.](../../image/clustering_visualized.png)

![](../../image/k_distance.png)

The k-distance plot shows relatively uniform distribution with steep rise at the end, indicating most points are at similar distances, which suggests that the density assumption of DBSCAN may not fit the data well.

# Conclusion

## Models Comparison

| Metric                      | NMF                                                              | DBSCAN                                              |
|-----------------------------|------------------------------------------------------------------|-----------------------------------------------------|
| Number of Topics (Clusters) | 5 topics                                                         | 1 cluster and 672 noise points                      |
| Topic Coherence             | High semantic coherence (political themes)                       | Low coherence (mainly noise, few points in cluster) |
| Topic Interpretation        | Relatively clear, interpretable topics (e.g., abortion, climate) | No distinct topics, mostly noise                    |
| k-distance Plot Analysis    | Not applicable (used for DBSCAN only)                            | Steep rise, indicating uniformity in distances      |

1.  **NMF performed better because:**

    -   Successfully identified 5 distinct and meaningful topics

    -   Clear semantic separation between topics

    -   Keywords within each topic show relevance and coherence

2.  **DBSCAN performed poorly because:**

    -   Only identified 1 cluster, marking most points as noise

    -   Unable to effectively distinguish different topic texts

    -   k-distance plot shows too uniform distribution, unsuitable for density-based clustering

## Discussion

A subsequent analysis was conducted using the same methodology without applying dimensionality reduction, which reinforced the initial conclusion that NMF outperforms DBSCAN. The consistent uniformity observed in the DBSCAN clustering results indicates that the text data may contain overlapping topics or that the density-based assumptions of the algorithm are not well-suited for capturing the diverse political themes present in the dataset.

Superisingly, applying NMF directly to the original data without dimensionality reduction yielded even better performance compared to the approach with dimensionality reduction. NMF successfully identified five significantly more distinctive topic groups, which can be manually categorized into 5 clear and interpretable themes. Therefore, in this project, clustering will proceed directly on the original data to more effectively support the development of subsequent supervised learning models.

| NMF Topic | Top Words Group                                                                           | Simplified Topic            |
|-----------|-------------------------------------------------------------------------------------------|-----------------------------|
| 0         | say, abortion, feel, get, want, right, make, woman, even, life                            | Abortion and Women’s Rights |
| 1         | gun, rifle, reddit, gun owner, owner, assault, assault rifle, law, health, couple         | Guns                        |
| 2         | tax, pay, pay tax, work, income, system, low, call, federal, amount                       | Tax                         |
| 3         | climate, change, climate change, call, point, news, article, insurance, meat, help        | Climate                     |
| 4         | vote, election, conservative, end, communist, worker, last, voting, socialist, democratic | Politics                    |

## **Visualization**

![](../../image/topics.png)

The NMF results (without dimensionality reduction) reveal that 69.3% of the topics focus on abortion and women's rights, making it the the most frequently discussed theme and significantly outnumbering other topics. In contrast, discussions about taxes are the least represented, comprising only 5.1% of the topics. The remaining three topics—climate change, gun control, and politics—account for a moderate share, ranging between 7% and 10% each.
