---
title: "Unsupervised Learning"
bibliography: ../../assets/references.bib
output: html_document
---

# Overview

Unsupervised learning is a type of machine learning that involves training a model without labeled data, meaning the algorithm attempts to identify patterns or structures from the input data by itself. The goal is to explore the underlying structure of the data without predefined labels or outcomes.

In this project, unsupervised learning including NMF (Non-negative Matrix Factorization) and DBSCAN (Density-Based Spatial Clustering of Applications with Noise) were used to group similar items without predefined labels, automatically discovering hidden topics and categorizing text data into clusters based on similarities, without prior knowledge of categories.

1.  **PCA (Principal Component Analysis):**
    -   Apply PCA to your dataset.
    -   Determine the optimal number of principal components.
    -   Visualize the reduced-dimensional data.
    -   Analyze and interpret the results.
2.  **t-SNE (t-distributed Stochastic Neighbor Embedding):**
    -   Implement t-SNE on the same dataset.
    -   Experiment with different perplexity values.
    -   Visualize the t-SNE output to reveal patterns and clusters.
    -   Compare the results of t-SNE with those from PCA.
3.  **Evaluation and Comparison:**
    -   Evaluate the effectiveness of PCA and t-SNE in preserving data structure.
    -   Compare the visualization capabilities of both techniques.
    -   Discuss the trade-offs and scenarios where one technique may perform better than the other.

# NMF

NMF is a factorization technique that decomposes a matrix (in this case, the term-document matrix) into two non-negative matrices: one representing topics and the other representing words. NMF is particularly useful for discovering parts-based representations in data, making it suitable for text data where topics can be described by sets of relevant words.

#### Reasons for Choosing NMF:

-   **Topic interpretability:** NMF generates topics that are easy to interpret as a set of related words.

-   **Sparsity:** NMF’s non-negative constraints ensure that the factorization results in interpretable and additive topic compositions, which is important for identifying meaningful topics.

## Process

1.  **Text Preprocessing:** The text is first cleaned by removing stopwords, performing lemmatization, and retaining only nouns, adjectives, verbs, and adverbs.

2.  **TF-IDF Vectorization:** The text data is transformed into a sparse matrix of term frequency-inverse document frequency (TF-IDF) features.

3.  **Topic Modeling with NMF:** The NMF model is trained with 5 topics, using the TF-IDF features. The model identifies the topics by associating high-weighted words with each topic.

4.  **Topic Assignment:** The highest topic probabilities for each document are assigned, and a topic label is associated with each submission.

## **Results**

**NMF Topics:**

-   **Topic 0**: say, abortion, feel, get, want, right, make, woman, even, life

-   **Topic 1**: gun, rifle, reddit, gun owner, owner, assault, assault rifle, law, health, couple

-   **Topic 2**: tax, pay, pay tax, work, income, system, low, call, federal, amount

-   **Topic 3**: climate, change, climate change, call, point, news, article, insurance, meat, help

-   **Topic 4**: vote, election, conservative, end, communist, worker, last, voting, socialist, democratic

**Manually Simplified Topics:**

-   **Topic 0**: Abortion and Women’s Rights

-   **Topic 1**: Guns

-   **Topic 2**: Tax

-   **Topic 3**: Climate

-   **Topic 4**: Politics

# DBSCAN

DBSCAN is a density-based clustering algorithm that groups together closely packed points and marks isolated points as noise. Unlike other clustering algorithms, DBSCAN does not require the number of clusters to be specified in advance.

#### Reasons for Choosing DBSCAN:

-   **Noise Handling:** DBSCAN can handle noisy data and outliers effectively.

-   **Cluster Shape Flexibility:** It does not assume spherical clusters, making it suitable for data with irregular cluster shapes.

## Process

1.  **TF-IDF Vectorization:** The text data is transformed into TF-IDF vectors, similar to the NMF approach.

2.  **Standardization:** The TF-IDF vectors are standardized (scaled) before applying DBSCAN to ensure that all features are treated equally.

3.  **Clustering with DBSCAN:** DBSCAN is applied to the scaled TF-IDF vectors with an `eps` value of 0.5 and a minimum sample count of 5. The algorithm attempts to cluster the data and identifies outliers as noise.

4.  **Validation with k-distance Plot:** The k-distance plot is generated to analyze the density distribution, showing that most points are equidistant, which may indicate poor clustering performance.

## **Results**

-   **1 Cluster Identified:** DBSCAN finds only 1 cluster, with 648 samples marked as noise (-1) and 29 samples assigned to cluster 0.
-   **K-Distance Plot:** The plot shows relatively uniform distribution with steep rise at the end, indicating most points are at similar distances, which suggests that the density assumption of DBSCAN may not fit the data well.

![](../../image/k_distance.png)

# Conclusion

## Models Comparison

| dbscan_cluster | -1  | 0   |
|:---------------|:----|:----|
| nmf_topic      |     |     |
| 0              | 427 | 29  |
| 1              | 61  | 0   |
| 2              | 45  | 0   |
| 3              | 52  | 0   |
| 4              | 63  | 0   |

| Metric                    | NMF                                                   | DBSCAN                                              |
|-------------------|------------------------------|--------------------------------|
| Number of Clusters/Topics | 5 distinct topics                                     | 1 cluster and 648 noise points                      |
| Topic Coherence           | High semantic coherence (political themes)            | Low coherence (mainly noise, few points in cluster) |
| Model Effectiveness       | Successful in identifying meaningful topics           | Failed to capture distinct topics                   |
| Cluster Interpretation    | Clear, interpretable topics (e.g., abortion, climate) | No distinct topics, mostly noise                    |
| k-distance Plot Analysis  | Not applicable (used for DBSCAN only)                 | Steep rise, indicating uniformity in distances      |

1.  **NMF performed better because:**

    -   Successfully identified 5 distinct and meaningful topics

    -   Clear semantic separation between topics

    -   Keywords within each topic show relevance and coherence

2.  **DBSCAN performed poorly because:**

    -   Only identified 1 cluster, marking most points as noise

    -   Unable to effectively distinguish different topic texts

    -   k-distance plot shows too uniform distribution, unsuitable for density-based clustering

## Summary

-   **NMF Performance:** NMF successfully extracted 5 distinct and interpretable topics related to political themes such as abortion, guns, taxes, climate change, and politics. The topics show semantic coherence and clear distinction.

-   **DBSCAN Performance:** DBSCAN performed poorly by grouping almost all data points as noise and failing to identify multiple clusters. The k-distance plot showed a uniform distribution of distances, which made it unsuitable for identifying clear text clusters in this case.

Thus, **NMF** outperformed **DBSCAN** in terms of topic identification in this task, with DBSCAN unable to effectively capture the varying political themes in the data. The uniformity observed in the DBSCAN clustering suggests that the text data may have overlapping topics or that the density-based assumption of the algorithm is not suitable for this task.
